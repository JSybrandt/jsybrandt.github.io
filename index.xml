<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Justin Sybrandt</title>
    <link>/</link>
    <description>Recent content on Justin Sybrandt</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 06 Jul 2021 11:20:00 -0500</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CBAG: Conditional Biomedical Abstract Generation</title>
      <link>/publications/cbag/</link>
      <pubDate>Tue, 06 Jul 2021 11:20:00 -0500</pubDate>
      
      <guid>/publications/cbag/</guid>
      <description>Abstract: Biomedical research papers often combine disjoint concepts in novel ways, such as when describing a newly discovered relationship between an understudied gene with an important disease. These concepts are often explicitly encoded as metadata keywords, such as the author-provided terms included with many documents in the MEDLINE database. While substantial recent work has addressed the problem of text generation in a more general context, applications, such as scientific writing assistants, or hypothesis generation systems, could benefit from the capacity to select the specific set of concepts that underpin a generated biomedical text.</description>
    </item>
    
    <item>
      <title>Accelerating COVID-19 research with graph mining and transformer-based learning</title>
      <link>/publications/2021_02_10_accelerating/</link>
      <pubDate>Wed, 10 Feb 2021 01:01:01 -0100</pubDate>
      
      <guid>/publications/2021_02_10_accelerating/</guid>
      <description>In 2020, the White House released the, &amp;ldquo;Call to Action to the Tech Community on New Machine Readable COVID-19 Dataset,&amp;rdquo; wherein artificial intelligence experts are asked to collect data and develop text mining techniques that can help the science community answer high-priority scientific questions related to COVID-19. The Allen Institute for AI and collaborators announced the availability of a rapidly growing open dataset of publications, the COVID-19 Open Research Dataset (CORD-19).</description>
    </item>
    
    <item>
      <title>Accelerating Text Mining Using Domain-Specific Stop Word Lists</title>
      <link>/publications/2020_12_10_accelerating_text_mining/</link>
      <pubDate>Thu, 10 Dec 2020 01:01:01 -0100</pubDate>
      
      <guid>/publications/2020_12_10_accelerating_text_mining/</guid>
      <description>Text preprocessing is an essential step in text mining. Removing words that can negatively impact the quality of prediction algorithms or are not informative enough is a crucial storage-saving technique in text indexing and results in improved computational efficiency. Typically, a generic stop word list is applied to a dataset regardless of the domain. However, many common words are different from one domain to another but have no significance within a particular domain.</description>
    </item>
    
    <item>
      <title>Exploiting Latent Features of Text and Graphs</title>
      <link>/publications/2020_05_07_dissertation/</link>
      <pubDate>Thu, 07 May 2020 01:01:01 -0100</pubDate>
      
      <guid>/publications/2020_05_07_dissertation/</guid>
      <description>The fastest growing online data sources include unstructured text and large graphs. These data are particularly prevalent in biomedical science, as large databases of scientific papers and archives of experimentally derived relationships entomb a vast amount of knowledge. While collections of text and graphs may be useful for human readers to understand, their ever-expanding size and scope creates a scalability challenge. To aid human researchers in scientific explorations, we propose new techniques that enable machine understanding of scientific text and graphs.</description>
    </item>
    
    <item>
      <title>Agatha talk with AISC</title>
      <link>/updates/2020_04_01_aisc_talk/</link>
      <pubDate>Wed, 01 Apr 2020 15:26:12 -0400</pubDate>
      
      <guid>/updates/2020_04_01_aisc_talk/</guid>
      <description>I was very happy to have a chance to talk about my recent work Agatha with the great people over at the A.I. Socratic Circles group! The talk was a &amp;ldquo;lunch &amp;amp; learn&amp;rdquo; recorded from quarantine, and broadcaster on YouTube. Check it out if you&amp;rsquo;re interested in Agatha but missed the live session!
Here&amp;rsquo;s the slides:
 </description>
    </item>
    
    <item>
      <title>Unsupervised Hierarchical Graph Representation Learning by Mutual Information Maximization</title>
      <link>/publications/2020_04_03_unsupervised_graph/</link>
      <pubDate>Wed, 01 Apr 2020 11:19:52 -0500</pubDate>
      
      <guid>/publications/2020_04_03_unsupervised_graph/</guid>
      <description>Abstract: Graph representation learning based on graph neural networks (GNNs) can greatly improve the performance of downstream tasks, such as node and graph classification. However, the general GNN models do not aggregate node information in a hierarchical manner, and can miss key higher-order structural features of many graphs. The hierarchical aggregation also enables the graph representations to be explainable. In addition, supervised graph representation learning requires labeled data, which is expensive and error-prone.</description>
    </item>
    
    <item>
      <title>Tips for Succeeding in a CS Ph.D.</title>
      <link>/posts/2020_03_30_tips_phd_cs/</link>
      <pubDate>Sun, 29 Mar 2020 13:42:36 -0400</pubDate>
      
      <guid>/posts/2020_03_30_tips_phd_cs/</guid>
      <description>Now that I am wrapping up my Ph.D., an endeavor that has defined my last four years, it seems as good a time as any to take stock of the advice I&amp;rsquo;ve given and received. I&amp;rsquo;m recording this mostly for myself, in hopes that a few years from now I might do this again and compare notes. However, I also hope that if any up-and-coming grad students stumble on this list, maybe it might do some good.</description>
    </item>
    
    <item>
      <title>Dissertation Defense</title>
      <link>/updates/defense_slides/</link>
      <pubDate>Fri, 27 Mar 2020 15:26:12 -0400</pubDate>
      
      <guid>/updates/defense_slides/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>AGATHA: Automatic Graph-mining And Transformer based Hypothesis generation Approach</title>
      <link>/publications/agatha/</link>
      <pubDate>Thu, 13 Feb 2020 11:19:52 -0500</pubDate>
      
      <guid>/publications/agatha/</guid>
      <description>Abstract: Medical research is risky and expensive. Drug discovery, as an example, requires that researchers efficiently winnow thousands of potential targets to a small candidate set for more thorough evaluation. However, research groups spend significant time and money to perform the experiments necessary to determine this candidate set long before seeing intermediate results. Hypothesis generation systems address this challenge by mining the wealth of publicly available scientific information to predict plausible research directions.</description>
    </item>
    
    <item>
      <title>Lecture: Survey of Text Mining</title>
      <link>/updates/survey_of_text_mining/</link>
      <pubDate>Tue, 19 Nov 2019 12:19:06 -0500</pubDate>
      
      <guid>/updates/survey_of_text_mining/</guid>
      <description>How to solve complex problems with text.
This talk was given at the Clemson Applied Data Science course on November 10&amp;rsquo;th, 2019. It is supposed to give people new to machine learning an overview of whats been going on in the world of text mining, with very little assumed prior knowledge.
Although we do go quickly from Bag-of-Word and TF-IDF to modern transformer models, this talk should serve as a solid entry point for anyone interested in the field.</description>
    </item>
    
    <item>
      <title>  Inhibition of the DDX3 prevents HIV-1 Tat and cocaine-induced neurotoxicity by
  targeting microglia activation
</title>
      <link>/publications/inhibition_of_ddx3/</link>
      <pubDate>Tue, 19 Nov 2019 12:12:22 -0400</pubDate>
      
      <guid>/publications/inhibition_of_ddx3/</guid>
      <description>Abstract: HIV-1 Associated Neurocognitive Disorder (HAND) is commonly seen in HIV-infected patients. Viral proteins including Tat cause neuronal toxicity and is worsened by drugs of abuse. To uncover potential targets for anti-HAND therapy, we employed a literature mining system, MOLIERE. Here, we validated Dead Box RNA Helicase 3 (DDX3) as a target to treat HAND via a selective DDX3 inhibitor, RK-33. The combined neurotoxicity of Tat protein and cocaine was blocked by RK-33 in rat and mouse cortical cultures.</description>
    </item>
    
    <item>
      <title>  Using Drive-by Health Monitoring to Detect Bridge Damage Considering
  Environmental and Operational Effects
</title>
      <link>/publications/drive_by_health_monitoring/</link>
      <pubDate>Tue, 19 Nov 2019 10:13:01 -0400</pubDate>
      
      <guid>/publications/drive_by_health_monitoring/</guid>
      <description>Abstract: Drive-by Health Monitoring utilizes accelerometers mounted on vehicles to gather dynamic response data that can be used to continuously evaluate the health of bridges faster and with less equipment than traditional structural health monitoring practices. Because vehicles and bridges create a coupled system, vehicle acceleration data contains information about bridge frequencies that can be used as health indicators. However, for drive-by health monitoring to be viable, variabilities in dynamic measurements caused by environmental and operational parameters, such as temperature, vehicle speed, traffic, and surface roughness need to be considered.</description>
    </item>
    
    <item>
      <title>The Basic Math of Neural Networks</title>
      <link>/posts/math_of_neural_networks/</link>
      <pubDate>Wed, 06 Nov 2019 14:18:52 -0400</pubDate>
      
      <guid>/posts/math_of_neural_networks/</guid>
      <description>The following are some slides from a recent talk internal to our lab group at Clemson. Covers the absolute fundamentals of neural networks and back propagation.
 </description>
    </item>
    
    <item>
      <title>Facebook Intern Executive Dinner</title>
      <link>/updates/facebook_exec_dinner/</link>
      <pubDate>Fri, 11 Oct 2019 12:19:06 -0500</pubDate>
      
      <guid>/updates/facebook_exec_dinner/</guid>
      <description>img { width: 400px; }  While this meeting was a surreal experience, my cohort of interns and I had a good conversation (once our initial nervousness finally settled).</description>
    </item>
    
    <item>
      <title>Hypergraph Partitioning with Embeddings</title>
      <link>/publications/partition_with_embeddings/</link>
      <pubDate>Mon, 09 Sep 2019 01:34:08 -0400</pubDate>
      
      <guid>/publications/partition_with_embeddings/</guid>
      <description>Abstract: The problem of placing circuits on a chip or distributing sparse matrix operations can be modeled as the hypergraph partitioning problem. A hypergraph is a generalization of the traditional graph wherein each &amp;ldquo;hyperedge&amp;rdquo; may connect any number of nodes. Hypergraph partitioning, therefore, is the NP-Hard problem of dividing nodes into $k$ similarly sized disjoint sets while minimizing the number of hyperedges that span multiple partitions. Due to this problem&amp;rsquo;s complexity, many partitioners leverage the multilevel heuristic of iteratively &amp;ldquo;coarsening&amp;rdquo; their input to a smaller approximation until an inefficient algorithm becomes feasible.</description>
    </item>
    
    <item>
      <title>Partition Hypergraphs with Embeddings (HG Details)</title>
      <link>/misc/partition_with_embeddings_supl_hg_table/</link>
      <pubDate>Mon, 26 Aug 2019 00:14:35 -0400</pubDate>
      
      <guid>/misc/partition_with_embeddings_supl_hg_table/</guid>
      <description>Go back to publication. Details The following table demonstrates many different aspects of all considered hypergraphs. This information compliments the other results presented in the supplimental information of &amp;ldquo;Partition Hypergraphs with Embeddings.&amp;rdquo;
Click Here to return to the rest of the supplimental information.
 .large_scroll_table { display: block; width:100%; table-layout: fixed; } thead { display: block; } tbody { display:block; height: 500px; overflow-y: auto; }     Node Degree Edge Degree   Hypergraph   # Nodes   # Edges   Med.</description>
    </item>
    
    <item>
      <title>Partition Hypergraphs with Embeddings (Supplemental Info.)</title>
      <link>/misc/partition_with_embeddings_supl/</link>
      <pubDate>Sun, 21 Jul 2019 00:14:35 -0400</pubDate>
      
      <guid>/misc/partition_with_embeddings_supl/</guid>
      <description>Go back to publication.
Data Download our full results as a MongoDB Database dump. Explore these results within MongoDB with the mongorestore command. More information can be found here.
Data Visualization Select the desired comparison using the following buttons. Then, click a cell in the resulting matrix plot to view a graph-wise comparison.
 #matrix_content { } .large_img { zoom:.25; } .btn-group { margin:auto; display: flex; flex-direction: row; justify-content: center; margin-bottom: 10pt; } .</description>
    </item>
    
    <item>
      <title>Embeddings Conceptualized</title>
      <link>/posts/embeddings_conceptualized/</link>
      <pubDate>Wed, 17 Jul 2019 22:40:43 -0400</pubDate>
      
      <guid>/posts/embeddings_conceptualized/</guid>
      <description>I&amp;rsquo;ve found it interesting how a lot of the conversation about embedding models and other neural network models haven&amp;rsquo;t really converged. Something that seems to complicate the issue is that Tensorflow as an object called &amp;ldquo;Embedding&amp;rdquo;. So the following describes some high-level understanding about how neural networks relate to other embedding methods.
So an &amp;ldquo;embedding&amp;rdquo; is a simplified vector representation of something, and I phrase it like that because embeddings happen everywhere for neural networks, not just for text.</description>
    </item>
    
    <item>
      <title>FOBE and HOBE: First- and High-Order Bipartite Embeddings</title>
      <link>/publications/bipartite_graph_embedding/</link>
      <pubDate>Tue, 16 Jul 2019 22:59:55 -0400</pubDate>
      
      <guid>/publications/bipartite_graph_embedding/</guid>
      <description>Abstract: Typical graph embeddings may not capture type-specific bipartite graph features that arise in such areas as recommender systems, data visualization, and drug discovery. Machine learning methods utilized in these applications would be better served with specialized embedding techniques. We propose two embeddings for bipartite graphs that decompose edges into sets of indirect relationships between node neighborhoods. When sampling higher-order relationships, we reinforce similarities through algebraic distance on graphs. We also introduce ensemble embeddings to combine both into a best of both worlds embedding.</description>
    </item>
    
    <item>
      <title>Submit a Moliere Query</title>
      <link>/misc/moliere_run_query/</link>
      <pubDate>Mon, 15 Jul 2019 21:14:35 -0400</pubDate>
      
      <guid>/misc/moliere_run_query/</guid>
      <description>Thanks for requesting a Moliere query! By using this form you are requesting us to run your experiment on our supercomputing infrastructure. Unfortunately, we have not been able to automate this process, so please allow for a little turn around time, and feel free to send us an email if you don&amp;rsquo;t hear back soon.
 Post Query  Query Terms Number of Topics (typically btwn. 10 - 100) Contact Email:   </description>
    </item>
    
    <item>
      <title>Thesis Proposal Presentation</title>
      <link>/updates/thesis_proposal/</link>
      <pubDate>Fri, 10 May 2019 14:18:52 -0400</pubDate>
      
      <guid>/updates/thesis_proposal/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>From BigData&#39;18 in Seattle</title>
      <link>/updates/big_data_2018/</link>
      <pubDate>Mon, 10 Dec 2018 14:18:52 -0400</pubDate>
      
      <guid>/updates/big_data_2018/</guid>
      <description>I&amp;rsquo;m here in Seattle, WA attending the IEEE International Conference on Big Data. I&amp;rsquo;ll be presenting two recent works. The first, presents a new method to validate hypothesis generation systems. The second, uses that method to determine the quality of input papers needed to make good conclusions. With two papers in the same conference, I will be giving a double-length talk! If you&amp;rsquo;re around, I&amp;rsquo;ll be at the end of the L12 session Wednesday morning.</description>
    </item>
    
    <item>
      <title>  Large-Scale Validation of Hypothesis Generation Systems via Candidate Ranking
</title>
      <link>/publications/automatic_validation/</link>
      <pubDate>Thu, 18 Oct 2018 22:43:39 -0400</pubDate>
      
      <guid>/publications/automatic_validation/</guid>
      <description>Abstract: The first step of many research projects is to define and rank a short list of candidates for study. In the modern rapidity of scientific progress, some turn to automated hypothesis generation (HG) systems to aid this process. These systems can identify implicit or overlooked connections within a large scientific corpus, and while their importance grows alongside the pace of science, they lack thorough validation. Without any standard numerical evaluation method, many validate general-purpose HG systems by rediscovering a handful of historical findings, and some wishing to be more thorough may run laboratory experiments based on automatic suggestions.</description>
    </item>
    
    <item>
      <title>Are Abstracts Enough for Hypothesis Generation?</title>
      <link>/publications/are_abstracts_enough/</link>
      <pubDate>Thu, 18 Oct 2018 22:34:08 -0400</pubDate>
      
      <guid>/publications/are_abstracts_enough/</guid>
      <description>Abstract: The potential for automatic hypothesis generation (HG) systems to improve research productivity keeps pace with the growing set of publicly available scientific information. But as data becomes easier to acquire, we must understand the effect different textual data sources have on our resulting hypotheses. Are abstracts enough for HG, or does it need full-text papers? How many papers does an HG system need to make valuable predictions? How sensitive is a general-purpose HG system to hyperparameter values or input quality?</description>
    </item>
    
    <item>
      <title>Moliere Poster from Google PIRC</title>
      <link>/updates/pirc_poster_2018/</link>
      <pubDate>Sat, 14 Jul 2018 14:18:52 -0400</pubDate>
      
      <guid>/updates/pirc_poster_2018/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Basic Iterative Numeric Optimization</title>
      <link>/posts/basic_optimization/</link>
      <pubDate>Mon, 05 Mar 2018 21:58:36 -0400</pubDate>
      
      <guid>/posts/basic_optimization/</guid>
      <description>Today in a class, we were asked to write an iterative solver for numerical equations. Now, many students in the class did not have an optimization background, so for the benefit of everyone, I want to share a simple overview of this exercise and how to go about solving it.
The problem was stated as follows:
$$ M(a) = 2\times a + 14 $$ $$ G(b) = b - 2 $$</description>
    </item>
    
    <item>
      <title>Moliere Software Overhaul</title>
      <link>/updates/moliere_software_overhaul/</link>
      <pubDate>Wed, 28 Feb 2018 14:18:52 -0400</pubDate>
      
      <guid>/updates/moliere_software_overhaul/</guid>
      <description>Over the last couple of days, I have retooled MOLIERE into a system that anyone1 can deploy it and run their own queries. The code is over at the [default repo][moliere_repo]2 and should be pretty straightforward, the code even downloads raw data itself! Just run build_network.py and point it at a big parallel file systen &amp;mdash; in a few hours you&amp;rsquo;ll have your very own knowledge network!
This project was a pretty crazy conglomeration of everything I&amp;rsquo;ve been up to.</description>
    </item>
    
    <item>
      <title>Producer and Consumer Model in C&#43;&#43;</title>
      <link>/posts/producer_consumer_openmp_cpp/</link>
      <pubDate>Mon, 06 Nov 2017 23:18:26 -0400</pubDate>
      
      <guid>/posts/producer_consumer_openmp_cpp/</guid>
      <description>So recently, I needed to parallelize a lot of my old code. This initially seemed like a daunting task. Now its not like I&amp;rsquo;ve never had to write parallel code before, and its not like my task was that hard. My issue primarily came from a staunch unwillingness to look anything up. After all, I could just throw my problem into python, right?
While that may be true, the version of myself today would like to tell the version of myself from last week that the C++ solution is not as bad as I thought.</description>
    </item>
    
    <item>
      <title>Document Embedding Basics</title>
      <link>/posts/document_embedding/</link>
      <pubDate>Wed, 27 Sep 2017 14:18:52 -0400</pubDate>
      
      <guid>/posts/document_embedding/</guid>
      <description>In a previous post I talked about how tools like word2vec are used to numerically understand the meanings behind words. In this post, I&amp;rsquo;m going to continue that discussion by describing ways we can find numerical representations for whole documents. So, I&amp;rsquo;ll be assuming you&amp;rsquo;re already familiar with the concept of word embeddings.
Why do we need document embeddings? Many real-world applications need to understand the content of text which is longer than just a single word.</description>
    </item>
    
    <item>
      <title>Agile Project Management in Google Sheets</title>
      <link>/posts/agile_development_in_google_sheets/</link>
      <pubDate>Wed, 20 Sep 2017 15:00:00 -0400</pubDate>
      
      <guid>/posts/agile_development_in_google_sheets/</guid>
      <description>I think its way to hard to manage small projects. There are so many project planning platforms out there and they typically fall into one of two major pitfalls for small teams. Either they are free and simplistic, i.e. Trello, or they are expensive and complicated, i.e. Jira.
Of course, there are millions of people who make these systems work for them everyday, but in my experience I find that it is hard for a small, well-intentioned group to actually use these.</description>
    </item>
    
    <item>
      <title>Word Embedding Basics</title>
      <link>/posts/word_embedding/</link>
      <pubDate>Sun, 17 Sep 2017 14:18:26 -0400</pubDate>
      
      <guid>/posts/word_embedding/</guid>
      <description>Recently, in text mining circles, a new method of representing words has taken off. This has been due, in a large part, to recent papers from Mikolov et al. and tools like word2vec 1. Since then, many other projects have applied this concept to a wide variety of areas within data mining 2. So what is all the hype about? What are these embeddings and why do we need them?</description>
    </item>
    
    <item>
      <title>Hypothesis Generation Explained</title>
      <link>/posts/hypothesis_generation_explained/</link>
      <pubDate>Fri, 15 Sep 2017 23:18:26 -0400</pubDate>
      
      <guid>/posts/hypothesis_generation_explained/</guid>
      <description>Undiscovered Public Knowledge In the last couple of years, researchers worldwide have begun to develop a powerful new tool. By using data mining techniques, these scientists hope to one day put themselves out of a job.
It all began in the 80&amp;rsquo;s with a man named Don Swanson. He was the first to notice something that he called undiscovered public knowledge. He saw that no human could possibly read all of the available information on a given topic, and he guessed that there were some truths that no one actually knows, but have already been published.</description>
    </item>
    
    <item>
      <title>MOLIERE: Automatic Biomedical Hypothesis Generation System</title>
      <link>/publications/moliere/</link>
      <pubDate>Sun, 13 Aug 2017 22:49:09 -0400</pubDate>
      
      <guid>/publications/moliere/</guid>
      <description>Abstract: Hypothesis generation is becoming a crucial time-saving technique which allows biomedical researchers to quickly discover implicit connections between important concepts. Typically, these systems operate on domain-specific fractions of public medical data. MOLIERE, in contrast, utilizes information from over 24.5 million documents and does not limit the document vocabulary. At the heart of our approach lies a multi-modal and multi-relational network of biomedical objects extracted from several heterogeneous datasets from the National Center for Biotechnology Information (NCBI).</description>
    </item>
    
    <item>
      <title>From KDD&#39;17 in Halifax</title>
      <link>/updates/kdd_2017/</link>
      <pubDate>Thu, 10 Aug 2017 14:18:52 -0400</pubDate>
      
      <guid>/updates/kdd_2017/</guid>
      <description>This browser does not support PDFs. Please download the PDF to view it: Download PDF.
   </description>
    </item>
    
    <item>
      <title>  To Agile or Not to Agile: A Comparison of Software Development Methodologies
</title>
      <link>/publications/to_agile_or_not_to_agile/</link>
      <pubDate>Sat, 01 Apr 2017 22:56:59 -0400</pubDate>
      
      <guid>/publications/to_agile_or_not_to_agile/</guid>
      <description>Abstract: Since the Agile Manifesto, many organizations have explored agile development methods to replace traditional waterfall development. Interestingly, waterfall remains the most widely used practice, suggesting that there is something missing from the many &amp;ldquo;flavors&amp;rdquo; of agile methodologies. We explore seven of the most common practices to explore this, and evaluate each against a series of criteria centered around product quality and adherence to agile practices. We find that no methodology entirely replaces waterfall and summarize the strengths and weaknesses of each.</description>
    </item>
    
    <item>
      <title>Rapid Replication of Multi-Petabyte File Systems</title>
      <link>/publications/rapid_replication/</link>
      <pubDate>Mon, 16 Nov 2015 22:54:47 -0400</pubDate>
      
      <guid>/publications/rapid_replication/</guid>
      <description>Abstract: As file systems grow larger, tools which were once industry standard become unsustainable at scale. Today, large data sets containing hundreds of millions of files often take longer to traverse than to copy. The time needed to replicate a file system has grown from hours to weeks, an unrealistic wait for a backup. Distsync is our new utility that can quickly update an out-of-date file system replica. By utilizing General Parallel File System (GPFS) policy scans, distsync finds changed files without navigating between directories.</description>
    </item>
    
  </channel>
</rss>
