<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Justin Sybrandt</title>
    <link>http://sybrandt.com/post/</link>
    <description>Recent content in Posts on Justin Sybrandt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Justin Sybrandt</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Producer and Consumer Model in C&#43;&#43;</title>
      <link>http://sybrandt.com/post/producer-consumer-openmp-cpp/</link>
      <pubDate>Sat, 16 Sep 2017 23:18:26 -0400</pubDate>
      
      <guid>http://sybrandt.com/post/producer-consumer-openmp-cpp/</guid>
      <description>

&lt;p&gt;So recently, I have had to parallelize a lot of the code I&amp;rsquo;ve been working with.
This initially seemed like a daunting task.&lt;/p&gt;

&lt;p&gt;Not its not like I&amp;rsquo;ve never had to write parallel code before, and its not like my task was that hard, in principle, to modify.
My issue primarily came from a staunch unwillingness to look up the old &lt;em&gt;PRAGMA&lt;/em&gt; statements that I&amp;rsquo;ve forgotten.
After all, I could just throw my problem into python, right?&lt;/p&gt;

&lt;p&gt;While that may be true, the version of myself today would like to tell the version of myself from last week that the C++ solution is not as bad as I thought.&lt;/p&gt;

&lt;h2 id=&#34;the-task&#34;&gt;The Task&lt;/h2&gt;

&lt;p&gt;I have a really large file, and each of its 40 million lines corresponded to a different computation.
There were no dependencies between these lines, and the whole thing was just encoded as plain text.
A line consisted of an id followed by 500 floats, representing a vector in $\Re^{500}$.&lt;/p&gt;

&lt;p&gt;For each line, I just wanted to load the corresponding vector, and compute two vector distances.
Based on those distances, I would either keep the vector or throw it away.&lt;/p&gt;

&lt;p&gt;Sequentially, this took forever.&lt;/p&gt;

&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;There are two synchronization points in this task.
Firstly, each line from the file must be read sequentially.
Because the lines are of variable length, I can&amp;rsquo;t do any fancy parallel file system tricks to make loading faster.
Secondly, the resulting data structure, my collection of selected vectors, needs to be protected so two different threads don&amp;rsquo;t try to modify it at the same time.&lt;/p&gt;

&lt;p&gt;This means firstly that only a single thread can read from the time at a time, and only a single thread can store its results at a time.
That being said, we are only going to be saving a small fraction of the total vectors.
Also, other threads shouldn&amp;rsquo;t have to wait while the reading thread actually &lt;em&gt;parses&lt;/em&gt; the input.&lt;/p&gt;

&lt;p&gt;So the idea is pretty simple.
One thread should read from the data file, extracting each line as fast as possible.
We will call this the &lt;strong&gt;producer&lt;/strong&gt; thread because it produces work.
The &lt;strong&gt;consumer&lt;/strong&gt; threads will be all other threads.&lt;/p&gt;

&lt;p&gt;Whenever a new line is found, one of the available threads should take it and start parsing.
Once parsed, the thread can independently do its distance calculations.
If the conditions are right, then the thread should get a lock on the data structure, store its result, and repeat.&lt;/p&gt;

&lt;p&gt;In python that&amp;rsquo;s pretty much as easy as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pool.map(doWork, [line for line in file])
# Note: This line doesn&#39;t do EXACTLY what I just described, but you get the gist.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How on earth do you do that in C++?&lt;/p&gt;

&lt;h2 id=&#34;the-c-solution&#34;&gt;The C++ Solution&lt;/h2&gt;

&lt;p&gt;Okay, we are going to use &lt;a href=&#34;http://www.openmp.org/&#34; target=&#34;_blank&#34;&gt;OpenMP&lt;/a&gt; and their &lt;em&gt;#pragma&lt;/em&gt; statements.
For unfamiliar readers, these are statements that the compiler will use to do a lot of the gritty parallel work for us.
For the semi-familiar readers, you probably do something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#pragma omp parallel for
for(unsigned int i = 0; i &amp;lt; N; ++i){
  //Make Magic Happen
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above code block says &lt;em&gt;&amp;ldquo;Do the following for loop in parallel&amp;rdquo;&lt;/em&gt;.
Unsurprisingly, each iteration of the for loop is done be a different thread.
Unfortunately, there is no single &lt;em&gt;#pragma&lt;/em&gt; statement for our little producer-consumer idea described above.
That said, its easier than you might think.&lt;/p&gt;

&lt;p&gt;The code looks a little something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;DataStructure data;
ifstream fileStream;
string line;

// ...

#pragma omp parallel
{
#pragma omp single
  {
    while(getline(fileStream, line)){
#pragma omp task firstprivate(line)
      {
        Vector vec(line); // Parse line
        // Get Work Done
        if(condition_met){
#pragma omp critical
          data.add(line);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So whats going on?&lt;/p&gt;

&lt;p&gt;First thing first, we get our data setup before the &lt;em&gt;#pragma&lt;/em&gt; nonsense.
This is because once we enter these &lt;em&gt;#pragma&lt;/em&gt; statements, we are going to be in a new scope, and we won&amp;rsquo;t be able to get the data back out. We enter the new scope with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#pragma omp parallel
{
  // Everything here is run in parallel.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This says that the following block will be run using all the threads available on the system.
What confused me at first is that the next line seems to say the opposite:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#pragma omp single
{
  // Everything here is run by one thread.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This line says that the following block will be run on only &lt;strong&gt;one&lt;/strong&gt; of the many threads.
Whats important to note here is that the remaining threads still exist, and are waiting for work.
Its this &lt;em&gt;#pragma&lt;/em&gt; which allows us to set up our &lt;strong&gt;producer&lt;/strong&gt;.
We get our &lt;strong&gt;consumers&lt;/strong&gt; with this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#pragma omp task
{
  // A new thread takes this work.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This statement creates work for a &lt;strong&gt;consumer&lt;/strong&gt; to take on.
Our single producer thread creates a new task every time they enter the body of our loop.
The option &lt;strong&gt;firstprivate(line)&lt;/strong&gt; specifies that each task should copy over its own version of the &lt;strong&gt;line&lt;/strong&gt; variable.
That way, each thread doesn&amp;rsquo;t need to worry about it when the &lt;strong&gt;producer&lt;/strong&gt; gets a new line.&lt;/p&gt;

&lt;p&gt;Finally, we use the following to protect our data structure:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;#pragma omp critical
{
  // Only one thread can run this at a time.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By using the &lt;strong&gt;critical&lt;/strong&gt; keyword, we specify that only one thread is allowed to write to our data structure at a time.&lt;/p&gt;

&lt;p&gt;And that&amp;rsquo;s it!
Who knew it was so easy to set this up?
All we need to do now is compile our code with the &lt;em&gt;-fopenmp&lt;/em&gt; flag and we are off to the races.
I was able to use a 64 core machine at 100% using this method!
Hope this helps you too.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hypothesis Generation Explained</title>
      <link>http://sybrandt.com/post/hypothesis-generation-explained/</link>
      <pubDate>Fri, 15 Sep 2017 23:18:26 -0400</pubDate>
      
      <guid>http://sybrandt.com/post/hypothesis-generation-explained/</guid>
      <description>

&lt;h1 id=&#34;undiscovered-public-knowledge&#34;&gt;Undiscovered Public Knowledge&lt;/h1&gt;

&lt;p&gt;In the last couple of years, researchers worldwide have begun to develop a powerful new tool. By using data mining techniques, these scientists hope to one day put themselves out of a job.&lt;/p&gt;

&lt;p&gt;It all began in the 80&amp;rsquo;s with a man named Don Swanson. He was the first to notice something that he called undiscovered public knowledge. He saw that no human could possibly read all of the available information on a given topic, and he guessed that there were some truths that no one actually knows, but have already been published.&lt;/p&gt;

&lt;p&gt;Big ideas are often discovered when people from different backgrounds get together on the same team. These ideas crop up because cross-disciplinary collaboration brings in not only a new viewpoint, but people who entirely different sets of mental information. For example, the idea of DNA storage has been recently popularized by Harvard scientists as a way to keep massive amounts of digital data. This bioinformatic technology relies on the connection that DNA and SSD&amp;rsquo;s are both solutions to the same core problem: information storage.&lt;/p&gt;

&lt;p&gt;DNA was originally proposed as a means for data storage in 1964. Up until that point, there had been papers about DNA in medical journals, and there had been papers about hard drives in technical journals. Typically, doctors don&amp;rsquo;t tend to meet many people from IBM at dinner parties, so it was not likely that many doctors knew how hard drives worked, or IBM employees who could describe DNA&amp;rsquo;s storage capabilities. But without realizing it, both communities explored the same problem. This is an example of Don Swanson&amp;rsquo;s undiscovered public knowledge.&lt;/p&gt;

&lt;p&gt;Before 1964, no one was saying DNA had anything to do with hard drives, but there existed an implicit connection: both addressed information storage. If someone was capable of keeping all technical and medical literature in their head simultaneously, this connection might seem trivial. And now, looking back on it, the connection seems pretty clear to us. What we attempt to do with hypothesis generation is exactly this; we try to identify these implicit connections.
Current State of the Art&lt;/p&gt;

&lt;p&gt;Right now, most hypothesis generation systems are beginning to become really powerful, and almost all of them stick to the field of medicine. This is for two main reasons:  Firstly there is a wealth of public information available about medicine. PubMed.gov is a service which allows anyone to search for medical papers, and we can download all of them! This dataset consists of over 24.5 million papers dating all the way back to the late 1800&amp;rsquo;s.  Secondly, medicine is important! We are in the business of curing cancer with computers! Who doesn&amp;rsquo;t want to say that at a dinner party?  All of these systems tend to have a similar structure. They start with paper data from PubMed and typically select a subset of the literature they think is relevant to some particular inquiry. They might also take in some keyword data, gene data, or other domain specific information to help make their decision. After this the team applies some statistical and/or machine learning techniques eventually resulting in a program which allows a user to request some information.&lt;/p&gt;

&lt;p&gt;Right now, these systems are starting to be used in the real world. Drug companies use techniques like this to figure out what to do with their R&amp;amp;D budgets. Drug research is very costly and, like all research, results are not guaranteed. Hypothesis generation promises to give these companies a better return on their investments.That return can be even bigger when we start considering drug-repurposing.&lt;/p&gt;

&lt;p&gt;When a scientist develops a new drug to treat some disease, they typically focus on a specific biological function which the drug is intended to change. For example, a specific protein might be responsible for a viral disease, so drugs will focus on changing how that protein interacts in the body. If we later discover that the same protein is responsible for certain types of cancer, it is likely that we can use the same anti-viral drugs to treat them. This sort of discovery is perfect for hypothesis generation.&lt;/p&gt;

&lt;p&gt;Many current hypothesis generation systems require the user to specify two keywords, such as an anti-viral drug, and a protein for example. From this, the system could possibly discover types of cancer or the stages in cancer development. This discovery would imply to a human scientist that it is worthwhile to investigate this drug repurposing.&lt;/p&gt;

&lt;h1 id=&#34;moliere&#34;&gt;MOLIERE&lt;/h1&gt;

&lt;p&gt;In the last couple of months, I have worked on MOLIERE, a new hypothesis generation system that can find conceptual links within the entire PubMed data set. We built MOLIERE to be more generalized than other systems which limit their search to specific proteins or keywords. Instead, we process all 24.5 million medical papers and learn a whole lot about them. We still allow people to query for the links between two keywords, but we use some machine learning and natural language processing techniques to give that user a list of topics which we believe are connected to the search.&lt;/p&gt;

&lt;p&gt;We found that we can detect a lot of really interesting relationships. We did some tests using historical data, meaning we only looked at papers published before anyone had actually found these relationships, and we saw that MOLIERE could identify them anyway!&lt;/p&gt;

&lt;p&gt;One of our best results was around the gene DDX3. It has been known to be involved with the transmission of HIV, but more recently it has been found to be linked to cancer development. There exist viral drugs intended to help treat HIV by interacting with DDX3, and these have been prime repurposing candidates for cancer treatments. So to run our experiments, we went back to 2009 before any of this had been discovered.&lt;/p&gt;

&lt;p&gt;We looked for the associations between DDX3 and certain cancer concepts, primarily those involved with the &amp;ldquo;wnt signaling pathway.&amp;rdquo; Although I am not a biologist, it is my understanding that cancer cells spread to new parts of the body through this. The concepts which MOLIERE found all indicated that there is a strong relationship between DDX3 and the wnt signaling pathway. We even identify the types of interactions DDX3 has in this process.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Academic Website</title>
      <link>http://sybrandt.com/post/academic-wedbiste/</link>
      <pubDate>Fri, 15 Sep 2017 17:18:26 -0400</pubDate>
      
      <guid>http://sybrandt.com/post/academic-wedbiste/</guid>
      <description>&lt;p&gt;For the longest time I have been trying to figure out what is the best way to manage an academic website.
So far I&amp;rsquo;ve had two major issues.
Firstly, I don&amp;rsquo;t want to waste too much of my time setting the dang thing up.
Secondly, I&amp;rsquo;m not sure what to say.
Well all of that is going to change (it seems) thanks to this thing called Hugo and this fancy academic theme.&lt;/p&gt;

&lt;p&gt;At the time of writing, I am a second year Ph.D. student, so there is a lot to figure out.
That said, its been over a years worth of hair-pulling and number-crunching.
So hopefully some of what comes out on this site will help someone out there.
(Or at least, future employers will know how hard I tried).&lt;/p&gt;

&lt;p&gt;Anyway, on this new platform I am going to attempt to work on writing with a more casual tone.
I want to be able to present my work to both ivory tower elites as well as the typical layperson.
So expect posts about machine learning, programming, technology, and surviving this wild ride we call grad school.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
